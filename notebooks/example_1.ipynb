{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c3a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaddab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set logger and enforce reproducibility\n",
    "from GPErks.log.logger import get_logger\n",
    "from GPErks.utils.random import set_seed\n",
    "log = get_logger()\n",
    "seed = 8\n",
    "set_seed(seed)  # reproducible sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aa4037",
   "metadata": {},
   "source": [
    "**1D function example**: Forrester et al. (2008)\n",
    "\n",
    "$f(x) = (6x - 2)^2 \\sin(12x - 4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7695caac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to learn (normally a high-dimensional, expensive deterministic model)\n",
    "from GPErks.utils.test_functions import forrester\n",
    "f = lambda x: forrester(x)\n",
    "D = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ee852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataset\n",
    "from GPErks.gp.data.dataset import Dataset\n",
    "dataset = Dataset.build_from_function(\n",
    "    f,\n",
    "    D,\n",
    "    n_train_samples=10,\n",
    "    n_test_samples=10,\n",
    "    design=\"srs\",\n",
    "    seed=seed,\n",
    "    l_bounds=[0],\n",
    "    u_bounds=[1]  # can put None if, as in this case, parameters range in [0, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab8c2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose likelihood\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "likelihood = GaussianLikelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5a9328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose mean function\n",
    "from gpytorch.means import LinearMean\n",
    "mean_function = LinearMean(input_size=dataset.input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876efaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose covariance function (kernel)\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "kernel = ScaleKernel(RBFKernel(ard_num_dims=dataset.input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e10f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose metrics\n",
    "from torchmetrics import MeanSquaredError, R2Score\n",
    "metrics = [MeanSquaredError(), R2Score()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16eff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define experiment\n",
    "from GPErks.gp.experiment import GPExperiment\n",
    "experiment = GPExperiment(\n",
    "    dataset,\n",
    "    likelihood,\n",
    "    mean_function,\n",
    "    kernel,\n",
    "    n_restarts=3,\n",
    "    metrics=metrics,\n",
    "    seed=seed,  # reproducible training\n",
    "    learn_noise=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bbcb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose training options: device + optimizer\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "optimizer = torch.optim.Adam(experiment.model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9888454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "from GPErks.train.emulator import GPEmulator\n",
    "emulator = GPEmulator(experiment, device)\n",
    "emulator.train(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407e4e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference on stored test set\n",
    "x_test = dataset.X_test\n",
    "y_test = dataset.y_test\n",
    "\n",
    "y_mean, y_std = emulator.predict(x_test)\n",
    "\n",
    "for metric in metrics:\n",
    "    print( metric(\n",
    "        torch.from_numpy(y_mean), torch.from_numpy(y_test)\n",
    "        ).item()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a04de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perk n.1: automatic inference\n",
    "from GPErks.perks.inference import Inference\n",
    "inference = Inference(emulator)\n",
    "inference.summary()  # can be retrieved from inference.scores_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ad011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nice plotting\n",
    "x_train = dataset.X_train\n",
    "y_train = dataset.y_train\n",
    "\n",
    "xx = np.linspace(dataset.l_bounds[0], dataset.u_bounds[0], 1000)\n",
    "yy_mean, yy_std = emulator.predict(xx)\n",
    "yy_true = f(xx)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "height = 9.36111\n",
    "width = 5.91667\n",
    "fig, axis = plt.subplots(1, 1, figsize=(4*width/3, height/2))\n",
    "\n",
    "axis.plot(xx, yy_true, c=\"C0\", ls=\"--\", label=\"true function\")\n",
    "\n",
    "CI = 2\n",
    "axis.plot(xx, yy_mean, c=\"C0\", label=\"predicted mean\")\n",
    "axis.fill_between(\n",
    "    xx, yy_mean - CI * yy_std, yy_mean + CI * yy_std, color=\"C0\", alpha=0.15, label=\"~95% CI\"\n",
    ")\n",
    "axis.scatter(x_train, y_train, fc=\"C0\", ec=\"C0\", label=\"training data\")\n",
    "\n",
    "# axis.scatter(x_test, y_test, fc=\"none\", ec=\"C0\", label=\"testing data\")\n",
    "\n",
    "axis.legend(loc=\"best\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aacaa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check testing points\n",
    "inference.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff9ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw samples from the posterior distribution\n",
    "y_mean, y_std = emulator.predict(x_test)\n",
    "print(y_mean.shape)\n",
    "print(y_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fb6a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_samples = emulator.sample(x_test, n_draws=5)\n",
    "print(y_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d27c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_samples = emulator.sample(xx, n_draws=5)\n",
    "\n",
    "fig, axis = plt.subplots(1, 1, figsize=(4*width/3, height/2))\n",
    "\n",
    "for i, ys in enumerate(y_samples):\n",
    "    axis.plot(xx, ys, lw=0.8, label=f\"posterior sample #{i+1}\", zorder=1)\n",
    "    \n",
    "axis.plot(xx, yy_mean, c=\"k\", lw=2, ls=\"--\", label=\"posterior mean\", zorder=2)\n",
    "axis.scatter(x_train, y_train, fc=\"k\", ec=\"k\", label=\"training data\", zorder=2)\n",
    "\n",
    "axis.legend(loc=\"best\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10964d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
